{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTVd-_gBnadx"
      },
      "source": [
        "# **GitHub configuration**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3clO8qoCZ1"
      },
      "source": [
        "## **Configuring the account**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgL2Jr1hmdbJ"
      },
      "outputs": [],
      "source": [
        "# identifying into github\n",
        "import subprocess, gc, os, torch\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "!git config --global user.name \"Nuzz23\"\n",
        "!git config --global user.email \"nunzio.licalzi9@gmail.com\"\n",
        "output = subprocess.check_output(\"git config --global --list\", shell=True).decode('utf-8').split()\n",
        "\n",
        "# check if correctly identified\n",
        "assert len(output) >= 2, \"Wrong length\"\n",
        "assert output[0].split('=')[-1] == 'Nuzz23', 'wrong user name'\n",
        "assert output[1].split('=')[-1] == 'nunzio.licalzi9@gmail.com', 'wrong email'\n",
        "del output\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U31qKporn-3m"
      },
      "source": [
        "## **Cloning the repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syIMtQmKqqCe",
        "outputId": "2a947cde-39b4-438e-c869-233c2bcc5774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# if the cloned repository already exists delete it\n",
        "%cd /content\n",
        "%rm -rf sample_data\n",
        "if \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip():\n",
        "  !rm -rf MLDL_SemanticSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_SY-eLHn_Nf"
      },
      "outputs": [],
      "source": [
        "# clone the repository via token\n",
        "!git clone --quiet \"{os.getenv('GITHUB_TOKEN')}\"\n",
        "\n",
        "# check if cloned correctly\n",
        "assert \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip(), \"Not cloned correctly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p05zOK3JrwDz"
      },
      "source": [
        "# **installing and importing the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moO33Ymp6U6i",
        "outputId": "4ef62685-4d60-4705-d44f-3692f4fcc32e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'MLDL_SemanticSegmentation'\n",
            "/content/MLDL_SemanticSegmentation\n"
          ]
        }
      ],
      "source": [
        "# installing the required libraries\n",
        "%cd MLDL_SemanticSegmentation\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrWXhTroa6ef"
      },
      "source": [
        "### **Defining custom imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQZMkS7Pa6kp"
      },
      "outputs": [],
      "source": [
        "from stats import countFLOPS, latency\n",
        "from train.trainDeepLabV2 import initModelDeepLabV2\n",
        "from datasets.downloader import Downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIP9VRmeHxAC"
      },
      "source": [
        "# **DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNPLJE6343OE"
      },
      "source": [
        "## **Downloading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSmTnFwQy1C7",
        "outputId": "73db6a6f-31ff-43a3-c7a7-a2fa4e990ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error downloading CityScapes dataset: Command '['gdown', '--quiet', '1uINto6zVV0VY9h380Pnprt_PR0izLfzW', '-O', 'CityScapes.zip']' returned non-zero exit status 1. with id 1uINto6zVV0VY9h380Pnprt_PR0izLfzW\n",
            "Error downloading CityScapes dataset: Command '['gdown', '--quiet', '1O8VGxrdRgRCt8lw36SXFNPIvfYnDZvOs', '-O', 'CityScapes.zip']' returned non-zero exit status 1. with id 1O8VGxrdRgRCt8lw36SXFNPIvfYnDZvOs\n"
          ]
        }
      ],
      "source": [
        "if not Downloader().downloadCityScapes():\n",
        "  raise FileNotFoundError(\"CityScapes dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoDMwNmjcsRY"
      },
      "source": [
        "## **Weights of the pretrained model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4YuTay1BF06"
      },
      "outputs": [],
      "source": [
        "if not Downloader().downloadWeightsDeepLabV2():\n",
        "  raise FileNotFoundError(\"DeepLabV2 weights not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYWmQ9M4Hzbo"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpPJA8B689GJ"
      },
      "source": [
        "## **Main Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8GFNhhFTEOs6",
        "outputId": "bb1dd865-179e-4fcb-c058-50082a77b03a"
      },
      "outputs": [],
      "source": [
        "WIDTH, HEIGHT = 1024, 512\n",
        "\n",
        "model = initModelDeepLabV2(width=WIDTH, height=HEIGHT, pushWeights=False, enablePrintVal=True, restartTraining=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV8hMJikN65k",
        "outputId": "0247d4fa-a9f5-48d7-f06f-aa7e4a27326d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 36 time(s)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flops 374664739584\n",
            "latencyMean, latencyStd, fpMean, fpsStd 261.788982629776 11.064570867830977 3.8798695890840054 1.5657381373703696\n",
            "Numero totale di parametri: 43901068\n"
          ]
        }
      ],
      "source": [
        "print('flops', countFLOPS(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print('latencyMean, latencyStd, fpMean, fpsStd', *latency(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print(f\"Tot number of parameters: {sum(p.numel() for p in model.parameters())}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
