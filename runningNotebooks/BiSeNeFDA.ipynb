{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6oPkLDguraD"
      },
      "source": [
        "## **Configuring the account**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Ftxi1nuU4I"
      },
      "outputs": [],
      "source": [
        "import subprocess, gc, os\n",
        "# identifying into github\n",
        "!git config --global user.name \"Nuzz23\"\n",
        "!git config --global user.email \"nunzio.licalzi9@gmail.com\"\n",
        "output = subprocess.check_output(\"git config --global --list\", shell=True).decode('utf-8').split()\n",
        "\n",
        "# check if correctly identified\n",
        "assert len(output) >= 2, \"Wrong lenght\"\n",
        "assert output[0].split('=')[-1] == 'Nuzz23', 'wrong user name'\n",
        "assert output[1].split('=')[-1] == 'nunzio.licalzi9@gmail.com', 'wrong email'\n",
        "del output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"TOKENS.txt\", 'r', encoding='utf-8') as f:\n",
        "  for line in f:\n",
        "    os.environ[line.split('=')[0].strip()] = line.strip().split('=')[1].strip()"
      ],
      "metadata": {
        "id": "LnW48tqIxPx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfxtL71uuZH"
      },
      "source": [
        "## **Cloning the repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ad2J_LONu14E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb88f2f-8613-4701-ae82-967c8fc5e153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# if the cloned repository already exists delete it\n",
        "%cd /content\n",
        "%rm -rf sample_data\n",
        "if \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip():\n",
        "  !rm -rf MLDL_SemanticSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TxCUei2u4pQ"
      },
      "outputs": [],
      "source": [
        "# clone the repository via token\n",
        "!git clone --quiet \"{os.getenv(\"GITHUB_TOKEN\")}\"\n",
        "\n",
        "# check if cloned correctly\n",
        "assert \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip(), \"Not cloned correctly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R12eYw0V4pC5"
      },
      "source": [
        "# **LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3Vf88t_u64X"
      },
      "outputs": [],
      "source": [
        "# installing the required libraries\n",
        "%cd /content/MLDL_SemanticSegmentation\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VmaXJXN4tP2"
      },
      "source": [
        "## **CUSTOM IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz5GC7m50JfP"
      },
      "outputs": [],
      "source": [
        "from stats import countFLOPS, latency, evaluateLastEpoch\n",
        "from train.trainFDA import init_model\n",
        "from datasets.downloader import Downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPefbMJvPAC"
      },
      "source": [
        "# **DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZsL5E6kvWzR"
      },
      "source": [
        "## **Downloading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfNKyy35vVqF"
      },
      "outputs": [],
      "source": [
        "if not Downloader().downloadCityScapes():\n",
        "  raise FileNotFoundError(\"CityScapes dataset not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBIz9BqI01IJ"
      },
      "outputs": [],
      "source": [
        "if not Downloader().downloadGTA5():\n",
        "  raise FileNotFoundError(\"GTA5 dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15_bvE6eFo7z"
      },
      "source": [
        "# **MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjU8jiNt6E_y"
      },
      "outputs": [],
      "source": [
        "from datasets.dataAugmentation.horizontalFlip import HorizontalFlip\n",
        "from datasets.dataAugmentation.saltAndPepper import SaltAndPepper\n",
        "from datasets.dataAugmentation.gaussianBlur import GaussianBlur\n",
        "from datasets.dataAugmentation.colorJitter import ColorJitter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE, VAL_SIZE = (1280, 720), (1024, 512)\n",
        "\n",
        "model = init_model('bisenet', batchSize=4, learning_rate=5e-4, trainSize=TRAIN_SIZE, valSize=VAL_SIZE, momentum=0.9,\n",
        "                   augmentation=ColorJitter(p=0.50, hue=0.1),\n",
        "                   enablePrint=True, pushWeights=True, enablePrintVal=True, restartTraining=True)\n",
        "\n",
        "flops = countFLOPS(model, width=VAL_SIZE[0], height=VAL_SIZE[1])\n",
        "latencyMean, latencyStd, fpsMean, fpsStd = latency(model, width=VAL_SIZE[0], height=VAL_SIZE[1])\n",
        "\n",
        "evaluateLastEpoch(model)"
      ],
      "metadata": {
        "id": "3rhalPdzEIqs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}