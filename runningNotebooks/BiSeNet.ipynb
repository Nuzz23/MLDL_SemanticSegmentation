{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6oPkLDguraD"
      },
      "source": [
        "## **Configuring the account**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Ftxi1nuU4I"
      },
      "outputs": [],
      "source": [
        "import subprocess, os\n",
        "from dotenv import load_dotenv\n",
        "# identifying into github\n",
        "!git config --global user.name \"Nuzz23\"\n",
        "!git config --global user.email \"nunzio.licalzi9@gmail.com\"\n",
        "output = subprocess.check_output(\"git config --global --list\", shell=True).decode('utf-8').split()\n",
        "\n",
        "# check if correctly identified\n",
        "assert len(output) >= 2, \"Wrong lenght\"\n",
        "assert output[0].split('=')[-1] == 'Nuzz23', 'wrong user name'\n",
        "assert output[1].split('=')[-1] == 'nunzio.licalzi9@gmail.com', 'wrong email'\n",
        "del output\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"TOKENS.txt\", 'r', encoding='utf-8') as f:\n",
        "  for line in f:\n",
        "    os.environ[line.split('=')[0].strip()] = line.strip().split('=')[1].strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfxtL71uuZH"
      },
      "source": [
        "## **Cloning the repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad2J_LONu14E",
        "outputId": "37b20be8-b8cd-4e71-eb42-4ff433d15dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# if the cloned repository already exists delete it\n",
        "%cd /content\n",
        "%rm -rf sample_data\n",
        "if \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip():\n",
        "  !rm -rf MLDL_SemanticSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TxCUei2u4pQ",
        "outputId": "e7a773fc-b1d4-4da6-d7ae-db14b697332f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MLDL_SemanticSegmentation\n"
          ]
        }
      ],
      "source": [
        "# clone the repository via token\n",
        "!git clone --quiet \"{os.getenv('GITHUB_TOKEN')}\"\n",
        "\n",
        "# check if cloned correctly\n",
        "assert \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip(), \"Not cloned correctly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R12eYw0V4pC5"
      },
      "source": [
        "# **LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Vf88t_u64X",
        "outputId": "1ff70cb9-9b7e-4d34-91a7-97743e46d2b4"
      },
      "outputs": [],
      "source": [
        "# installing the required libraries\n",
        "%cd /content/MLDL_SemanticSegmentation\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALRdOLBF4szI"
      },
      "source": [
        "## **MAIN LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V3Zs69QvAvF"
      },
      "outputs": [],
      "source": [
        "import torch, wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VmaXJXN4tP2"
      },
      "source": [
        "## **CUSTOM IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz5GC7m50JfP"
      },
      "outputs": [],
      "source": [
        "from stats import countFLOPS, latency, evaluateLastEpoch\n",
        "from train.trainBiSeNetCity import initBiSeNetOrV2Base\n",
        "from datasets.downloader import Downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPefbMJvPAC"
      },
      "source": [
        "# **DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZsL5E6kvWzR"
      },
      "source": [
        "## **Downloading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfNKyy35vVqF"
      },
      "outputs": [],
      "source": [
        "if not Downloader().downloadCityScapes():\n",
        "  raise FileNotFoundError(\"CityScapes dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBThUMEkxLFy"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZpMj8QZMvIZ"
      },
      "outputs": [],
      "source": [
        "WIDTH, HEIGHT = 1024, 512\n",
        "\n",
        "model = initBiSeNetOrV2Base(model_str='bisenet', batchSize=4, learning_rate=0.0005, width=WIDTH, height=HEIGHT,\n",
        "                    pushWeights=True, enablePrintVal=True, enablePrint=True, restartTraining=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mt8nBDfYC3n",
        "outputId": "6fc4845f-cce3-4f6e-9d98-dfa860873049"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 2 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 4 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "context_path.features.avgpool, context_path.features.fc, supervision1, supervision2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flops 25779775698\n",
            "latencyMean, latencyStd, fpMean, fpsStd 15.839773893356325 2.301098004268971 64.58737348178171 13.600086919463912\n",
            "Numero totale di parametri: 12581672\n"
          ]
        }
      ],
      "source": [
        "print('flops', countFLOPS(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print('latencyMean, latencyStd, fpMean, fpsStd', *latency(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print(f\"Numero totale di parametri: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "evaluateLastEpoch(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
