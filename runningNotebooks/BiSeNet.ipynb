{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6oPkLDguraD"
      },
      "source": [
        "## **Configuring the account**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Ftxi1nuU4I"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "from dotenv import load_dotenv\n",
        "# identifying into github\n",
        "!git config --global user.name \"Nuzz23\"\n",
        "!git config --global user.email \"nunzio.licalzi9@gmail.com\"\n",
        "output = subprocess.check_output(\"git config --global --list\", shell=True).decode('utf-8').split()\n",
        "\n",
        "# check if correctly identified\n",
        "assert len(output) >= 2, \"Wrong lenght\"\n",
        "assert output[0].split('=')[-1] == 'Nuzz23', 'wrong user name'\n",
        "assert output[1].split('=')[-1] == 'nunzio.licalzi9@gmail.com', 'wrong email'\n",
        "del output\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfxtL71uuZH"
      },
      "source": [
        "## **Cloning the repository**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ad2J_LONu14E",
        "outputId": "37b20be8-b8cd-4e71-eb42-4ff433d15dfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "# if the cloned repository already exists delete it\n",
        "%cd /content\n",
        "%rm -rf sample_data\n",
        "if \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip():\n",
        "  !rm -rf MLDL_SemanticSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TxCUei2u4pQ",
        "outputId": "e7a773fc-b1d4-4da6-d7ae-db14b697332f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/MLDL_SemanticSegmentation\n"
          ]
        }
      ],
      "source": [
        "# clone the repository via token\n",
        "!git clone --quiet \"{os.getenv('GITHUB_TOKEN')}\"\n",
        "\n",
        "# check if cloned correctly\n",
        "assert \"MLDL_SemanticSegmentation\" in subprocess.check_output(\"ls\", shell=True).decode(\"utf-8\").strip(), \"Not cloned correctly\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R12eYw0V4pC5"
      },
      "source": [
        "# **LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3Vf88t_u64X",
        "outputId": "1ff70cb9-9b7e-4d34-91a7-97743e46d2b4"
      },
      "outputs": [],
      "source": [
        "# installing the required libraries\n",
        "%cd /content/MLDL_SemanticSegmentation\n",
        "%pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALRdOLBF4szI"
      },
      "source": [
        "## **MAIN LIBRARIES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5V3Zs69QvAvF"
      },
      "outputs": [],
      "source": [
        "import torch, wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VmaXJXN4tP2"
      },
      "source": [
        "## **CUSTOM IMPORTS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sz5GC7m50JfP"
      },
      "outputs": [],
      "source": [
        "from stats import countFLOPS, latency\n",
        "from models.bisenet.build_bisenet import BiSeNet\n",
        "from Extension.BiSeNetV2.model import BiSeNetV2\n",
        "from train import mainBiSeNetBase\n",
        "from datasets.downloader import Downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAPefbMJvPAC"
      },
      "source": [
        "# **DATASET**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZsL5E6kvWzR"
      },
      "source": [
        "## **Downloading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FfNKyy35vVqF"
      },
      "outputs": [],
      "source": [
        "if not Downloader().downloadCityScapes():\n",
        "  raise FileNotFoundError(\"CityScapes dataset not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBThUMEkxLFy"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5N_yB6R5Jfr"
      },
      "outputs": [],
      "source": [
        "def initBiSeNetOrV2Base(model_str:str='bisenet', totEpoches:int=50, width:int=1024, height:int=512, batchSize:int=4, momentum:float=0.9, learning_rate:float=0.0005,\n",
        "                restartTraining:bool=False, pushWeights:bool=False, enablePrint:bool=False, enablePrintVal:bool=False):\n",
        "    \"\"\"\n",
        "    Initializes the model and starts the training process.\n",
        "\n",
        "    Args:\n",
        "        totEpoches (int, optional): The total number of epochs to train the model. Defaults to 50.\n",
        "        width (int, optional): The width of the input image. Defaults to 1024.\n",
        "        height (int, optional): The height of the input image. Defaults to 512.\n",
        "        batchSize (int, optional): The batch size to use for training. Defaults to 4.\n",
        "        momentum (float, optional): The momentum to use for the optimizer. Defaults to 0.9.\n",
        "        learning_rate (float, optional): The learning rate to use for the optimizer. Defaults to 0.005.\n",
        "        restartTraining (bool, optional): Whether to restart the training process from scratch or use the weigths\n",
        "            of the previous training epoch. Defaults to False, ie start from scratch the training.\n",
        "        pushWeights (bool, optional): Whether to push the weights of the training to git. Defaults to False.\n",
        "        enablePrint (bool, optional): Whether to enable print of the images during training. Defaults to False.\n",
        "        enablePrintVal (bool, optional): Whether to enable print of the images during validation. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): The fully trained PyTorch model.\n",
        "    \"\"\"\n",
        "    assert torch.cuda.is_available(), \"Use cuda (T4 gpu not enabled)\"\n",
        "    wandb.login(key='53d3ed3ff56973b6eb203376a439b403344ea7d5')\n",
        "    wandb.init()\n",
        "\n",
        "    match model_str.lower() if isinstance(model_str, str) else model_str:\n",
        "        case 'bisenetv2': model = BiSeNetV2(n_classes=19).cuda()\n",
        "        case _: model, model_str = BiSeNet(num_classes=19, context_path='resnet18').cuda(), 'bisenet'\n",
        "\n",
        "    if restartTraining:\n",
        "        artifact = wandb.use_artifact(f'tempmailforme212-politecnico-di-torino/BiSeNetV2/model-weights:latest', type='model')\n",
        "        artifact_dir = artifact.download()\n",
        "\n",
        "        # Carica i pesi nel modello\n",
        "        weights_path = f\"{artifact_dir}/model_weights.pth\"\n",
        "        model.load_state_dict(torch.load(weights_path))\n",
        "\n",
        "        print(\"Correctly loaded weights from the cloud of WandB!\")\n",
        "\n",
        "        starting_epoch = artifact.metadata['epoch']\n",
        "    else:\n",
        "        starting_epoch = 0\n",
        "\n",
        "    wandb.init(project=f'BiSeNetV2',\n",
        "                config={\"starting_epoch\": starting_epoch, \"epoches\":totEpoches, 'weight_decay':1e-4,\n",
        "                        \"learning_rate\":learning_rate, \"momentum\":momentum,'batch_size':batchSize})\n",
        "\n",
        "    return mainBiSeNetBase(wandb, model, model_str, width, height, pushWeights, enablePrint, enablePrintVal)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZpMj8QZMvIZ"
      },
      "outputs": [],
      "source": [
        "WIDTH, HEIGHT = 1024, 512\n",
        "\n",
        "model = initBiSeNetOrV2Base(model_str='bisenet', batchSize=4, learning_rate=0.0005, width=WIDTH, height=HEIGHT,\n",
        "                   pushWeights=True, enablePrintVal=True, enablePrint=True, restartTraining=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mt8nBDfYC3n",
        "outputId": "6fc4845f-cce3-4f6e-9d98-dfa860873049"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::max_pool2d encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add_ encountered 8 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mean encountered 2 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::sigmoid encountered 3 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::mul encountered 4 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:Unsupported operator aten::add encountered 1 time(s)\n",
            "WARNING:fvcore.nn.jit_analysis:The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
            "context_path.features.avgpool, context_path.features.fc, supervision1, supervision2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "flops 25779775698\n",
            "latencyMean, latencyStd, fpMean, fpsStd 15.839773893356325 2.301098004268971 64.58737348178171 13.600086919463912\n",
            "Numero totale di parametri: 12581672\n"
          ]
        }
      ],
      "source": [
        "print('flops', countFLOPS(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print('latencyMean, latencyStd, fpMean, fpsStd', *latency(model, width=WIDTH, height=HEIGHT))\n",
        "\n",
        "print(f\"Numero totale di parametri: {sum(p.numel() for p in model.parameters())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_ylyZH77F8e"
      },
      "outputs": [],
      "source": [
        "from train import evaluateLastEpoch\n",
        "evaluateLastEpoch(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
